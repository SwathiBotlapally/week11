import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
# Load dataset
df = pd.read_csv("segmentation_data.csv")

df.head()
df.info()
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=42)
    kmeans.fit(scaled_features)
    wcss.append(kmeans.inertia_)

plt.plot(range(1, 11), wcss, marker='o')
plt.xlabel("Number of Clusters")
plt.ylabel("WCSS")
plt.title("Elbow Method")
plt.show()
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.cluster import AgglomerativeClustering

linked = linkage(scaled_features, method='ward')
dendrogram(linked)
plt.show()

hc = AgglomerativeClustering(n_clusters=3)
df['Hierarchical_Cluster'] = hc.fit_predict(scaled_features)
segment_summary = df.groupby('KMeans_Cluster').mean()
segment_summary
segment_names = {
    0: "Premium Spenders",
    1: "Budget Conscious",
    2: "Young Professionals"
}

df['Segment_Name'] = df['KMeans_Cluster'].map(segment_names)
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
results = []

for segment in df['Segment_Name'].unique():
    segment_df = df[df['Segment_Name'] == segment]
    
    X = segment_df[['Age', 'AnnualIncome', 'SpendingScore']]
    y = segment_df['Purchase']   # Target variable
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )
    
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
    
    results.append([
        segment,
        accuracy_score(y_test, y_pred),
        precision_score(y_test, y_pred),
        recall_score(y_test, y_pred),
        f1_score(y_test, y_pred),
        roc_auc_score(y_test, model.predict_proba(X_test)[:,1])
    ])
results_df = pd.DataFrame(results, columns=[
    'Segment', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'ROC_AUC'
])

results_df
results_df.to_csv("model_evaluation_results.csv", index=False)
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [5, 10, None]
}

grid = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=3,
    scoring='f1'
)

grid.fit(X_train, y_train)
grid.best_params_
df['Segment_Name'].value_counts(normalize=True) * 100
